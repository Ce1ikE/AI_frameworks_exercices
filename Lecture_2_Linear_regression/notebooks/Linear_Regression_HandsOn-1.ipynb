{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food Truck"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will implement linear regression with one variable to predict profits for a food truck.  <br>\n",
    "\n",
    "\n",
    "Suppose you are the CEO of a restaurant franchise and are considering different cities for opening a new outlet. The chain already has trucks in various cities and you have data for profits and populations from the cities. <br>\n",
    "\n",
    "\n",
    "The file food_truck.txt  contains the dataset for our linear regression exercise.  <br>\n",
    "\n",
    "\n",
    "The first column is the population of a city and the second column is the profit of a food truck in that city. A negative value for profit indicates a loss. <br>\n",
    "\n",
    "\n",
    "So. let's start. <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'Python 3.13.7' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('food_truck.txt', header = None, delimiter = \",\") #read from dataset\n",
    "X = data.iloc[:,0] # read first column, will be put in a 'series' variable\n",
    "print('X.shape: ', X.shape)\n",
    "y = data.iloc[:,1] # read second column, will be put in a 'series' variable\n",
    "print('y.shape: ', y.shape)\n",
    "m = len(y) # number of training example (97)\n",
    "print('Number of samples:', m)\n",
    "print(data.head()) # view first few rows of the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEEL FREE TO IMPROVE THE PLOT\n",
    "\n",
    "# Reading and Plotting the data\n",
    "# Before starting on any task, try to visualize the data. \n",
    "# You can use a scatter plot to visualize this data, since it has only two properties to plot (profit and population).\n",
    "# For multidimensional data : cannot be plotted on a 2-d or 3-d plot. \n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.xlabel('Population of City in 10,000s')\n",
    "plt.ylabel('Profit in $10,000s')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing and converting into an nparray, we want to make use of array manipulations (dot product). <br>\n",
    "\n",
    "In the following lines, we add another dimension to our data to accommodate the intercept term, we want to find the best values for Theta0 and Theta1 for the function:  <br>\n",
    "\n",
    "**y = Theta0 + Theta1 * x** <br> \n",
    "\n",
    "by getting the error/cost as small as possible.  <br>\n",
    "\n",
    "\n",
    "We also initialize the initial parameters theta to 0 and the learning rate alpha to 0.01. <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X)) # should be a pd.Series()\n",
    "X = X.to_numpy()[:,np.newaxis] # convert pd.Series() to an np.ndarray\n",
    "y = y.to_numpy()[:,np.newaxis] # convert pd.Series() to an np.ndarray\n",
    "\n",
    "# Will generate a warning:\n",
    "# Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
    "\n",
    "# # Better w/o warning\n",
    "# X = X.to_numpy()[:,np.newaxis] # convert pd.Series() to an np.ndarray\n",
    "# y = y.to_numpy()[:,np.newaxis] # convert pd.Series() to an np.ndarray\n",
    "\n",
    "theta = np.zeros([2,1]) # start off with a (0, 0) array\n",
    "iterations = 100000 # \n",
    "learning_rate = 0.01 # magic number, defines the increase in change in Theta in every iteration we take\n",
    "\n",
    "# apply the trick we saw in the classroom of 'all ones' for x0, so that we can use matrix multiplication\n",
    "# TAKE CARE WITH THE VARIABLE NAMES "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computting the cost (or error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(X_ones, y, theta):\n",
    "    # We are going to calculate the MSE (Mean Square Error). NOT the RMSE (Root Mean Square Error)\n",
    "    #\n",
    "    # FILL IN THE NECESSARY CODE. Return the cost.\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the initial error/cost with the current theta0 and theta1 values = 0?\n",
    "\n",
    "cost = computeCost(X_ones, y, theta)\n",
    "print(cost)\n",
    "# You get a cost of 32.072733877455676"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X_ones, y, theta, learning_rate, iterations):\n",
    "\n",
    "    # First work out what the partial derivatives are, then apply the gradientDescent \n",
    "    # Parameters:\n",
    "    # -----------\n",
    "    # X: matrix with the input variables\n",
    "    # y: the correct results\n",
    "    # iterations: The number of times the gradientDescent should run.\n",
    "    #\n",
    "    # FILL IN THE NECESSARY CODE.\n",
    "    # After the iterations are performed, return the theta0 and theta1 values.\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_refined = gradientDescent(X_ones, y, theta, learning_rate, iterations)\n",
    "print(theta_refined)\n",
    "###  This should result in\n",
    "#  [[-3.89578088]\n",
    "#  [ 1.19303364]]\n",
    "### "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the final cost (or error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_refined =  computeCost(X_ones, y, theta_refined)\n",
    "print(cost_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we improve on these results?\n",
    "# Try with different values for the number of iterations and with different learning rates\n",
    "# Try eg with as number of iterations: 500, 1500, 5000, 10000, 100000,...\n",
    "# Try a different learning rate: 0.1, 0.03, 0.01, 0.003, 0.001, ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost with 500    iterations : 4.713809531116866 <br>\n",
    "Cost with 1000   iterations : 4.515955503078912 <br>\n",
    "Cost with 1500   iterations : 4.483388256587726 <br>\n",
    "Cost with 10000  iterations : 4.476971375975179 <br>\n",
    "Cost with 100000 iterations : 4.476971375975179 <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualization of the Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,1], y)\n",
    "plt.xlabel('Population of City in 10,000s')\n",
    "plt.ylabel('Profit in $10,000s')\n",
    "plt.plot(X[:,1], np.dot(X, theta), color = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make some predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with Scikit-Learn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you already worked with Scikit-Learn. Apply the Linear regression from the Scikit-Learn and check if the results are the same.\n",
    "Are they? If no, why?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
