{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e0bbe10",
   "metadata": {},
   "source": [
    "# Compute gradient yourself using numpy (every step manually)\n",
    "\n",
    "Let's assume we want to use a model that implements linear regression.\n",
    "\n",
    "So we have a formula of the form `f = w * x` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c54fa10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-21T15:25:55.966997Z",
     "start_time": "2021-11-21T15:25:55.617187Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40122d02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-21T15:25:55.982997Z",
     "start_time": "2021-11-21T15:25:55.966997Z"
    }
   },
   "outputs": [],
   "source": [
    "# here : f = 2 * x\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
    "\n",
    "w = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e85d605a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-21T15:25:55.991001Z",
     "start_time": "2021-11-21T15:25:55.982997Z"
    }
   },
   "outputs": [],
   "source": [
    "# model output\n",
    "def forward(x):\n",
    "    return w * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dd9a2f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-21T15:25:56.007001Z",
     "start_time": "2021-11-21T15:25:55.991001Z"
    }
   },
   "outputs": [],
   "source": [
    "# loss = MSE\n",
    "def loss(y, y_pred):\n",
    "    return ((y_pred - y)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5552e3a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-21T15:25:56.023003Z",
     "start_time": "2021-11-21T15:25:56.007001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n"
     ]
    }
   ],
   "source": [
    "# Here we need to calculate the gradient of the loss-function ourselves.\n",
    "# Loss = MSE = 1/N * (w*x - y)**2\n",
    "# dLoss/dw = 1/N * 2 * (w*x - y) * x = 1/N * 2 * x * (w*x-y)\n",
    "def gradient(x, y, y_pred):\n",
    "    return np.dot(2*x, y_pred - y).mean()\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3166cb6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-21T15:25:56.038995Z",
     "start_time": "2021-11-21T15:25:56.023003Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c59dcaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-21T15:25:56.054999Z",
     "start_time": "2021-11-21T15:25:56.038995Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99f2a3f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-21T15:25:56.071733Z",
     "start_time": "2021-11-21T15:25:56.055716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: w = 1.200, loss = 30.00000000\n",
      "epoch 2: w = 1.680, loss = 4.79999924\n",
      "epoch 3: w = 1.872, loss = 0.76800019\n",
      "epoch 4: w = 1.949, loss = 0.12288000\n",
      "epoch 5: w = 1.980, loss = 0.01966083\n",
      "epoch 6: w = 1.992, loss = 0.00314570\n",
      "epoch 7: w = 1.997, loss = 0.00050332\n",
      "epoch 8: w = 1.999, loss = 0.00008053\n",
      "epoch 9: w = 1.999, loss = 0.00001288\n",
      "epoch 10: w = 2.000, loss = 0.00000206\n",
      "epoch 11: w = 2.000, loss = 0.00000033\n",
      "epoch 12: w = 2.000, loss = 0.00000005\n",
      "epoch 13: w = 2.000, loss = 0.00000001\n",
      "epoch 14: w = 2.000, loss = 0.00000000\n",
      "epoch 15: w = 2.000, loss = 0.00000000\n",
      "epoch 16: w = 2.000, loss = 0.00000000\n",
      "epoch 17: w = 2.000, loss = 0.00000000\n",
      "epoch 18: w = 2.000, loss = 0.00000000\n",
      "epoch 19: w = 2.000, loss = 0.00000000\n",
      "epoch 20: w = 2.000, loss = 0.00000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # predict = forward pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # calculate gradients\n",
    "    dw = gradient(X, Y, y_pred)\n",
    "\n",
    "    # update weights\n",
    "    w -= learning_rate * dw\n",
    "\n",
    "    if epoch % 1 == 0:   # Look at all epochs\n",
    "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
    "     \n",
    "print(f'Prediction after training: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a914f3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4a3b285",
   "metadata": {},
   "source": [
    "# Now, let's try with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acd9f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Design model (input, output, forward pass with different layers)\n",
    "# 2) Construct loss and optimizer\n",
    "# 3) Training loop\n",
    "#       - Forward = compute prediction and loss\n",
    "#       - Backward = compute gradients\n",
    "#       - Update weights\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62a28214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here : f = 2 * x\n",
    "\n",
    "# 0) Training samples, watch the shape!\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c80dc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#samples: 4, #features: 1\n"
     ]
    }
   ],
   "source": [
    "n_samples, n_features = X.shape\n",
    "print(f'#samples: {n_samples}, #features: {n_features}')\n",
    "# 0) create a test sample\n",
    "X_test = torch.tensor([5], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13de1bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = -3.745\n"
     ]
    }
   ],
   "source": [
    "# 1) Design Model, the model has to implement the forward pass!\n",
    "# Here we can use a built-in model from PyTorch\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "# we can call this model with samples X\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "'''\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        # define diferent layers\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model = LinearRegression(input_size, output_size)\n",
    "'''\n",
    "\n",
    "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cac56bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Define loss and optimizer\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da588f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 : w =  -0.22590675950050354  loss =  tensor(59.5198, grad_fn=<MseLossBackward0>)\n",
      "epoch  11 : w =  1.544162631034851  loss =  tensor(1.5593, grad_fn=<MseLossBackward0>)\n",
      "epoch  21 : w =  1.8317652940750122  loss =  tensor(0.0586, grad_fn=<MseLossBackward0>)\n",
      "epoch  31 : w =  1.8808295726776123  loss =  tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch  41 : w =  1.8914424180984497  loss =  tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch  51 : w =  1.8957899808883667  loss =  tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch  61 : w =  1.8990516662597656  loss =  tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch  71 : w =  1.902063012123108  loss =  tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch  81 : w =  1.9049607515335083  loss =  tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch  91 : w =  1.9077688455581665  loss =  tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "Prediction after training: f(5) = 9.815\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3) Training loop\n",
    "for epoch in range(n_iters):\n",
    "    # predict = forward pass with our model\n",
    "    y_predicted = model(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_predicted)\n",
    "\n",
    "    # calculate gradients = backward pass\n",
    "    l.backward()\n",
    "\n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero the gradients after updating\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        [w, b] = model.parameters() # unpack parameters\n",
    "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l)\n",
    "\n",
    "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20563ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "interpreter": {
   "hash": "360887b9cab5489ef98dcd0c24153a5025959100434b1781469b024af9ed3ee4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
